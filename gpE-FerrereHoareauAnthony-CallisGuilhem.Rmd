---
title: "Projet Analyse de Donnée"
author: "FERRERE HOAREAU Anthony et CALLIS Guilhem"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
Chargement du jeux de donnée:

```{r echo=F}
if (!require("ggplot2")) install.packages("ggplot2")
library("ggplot2")
DataBio = read.table("DataProjet3MIC-2425.txt", header=TRUE)
#affichage de la nature des variable du jeu de donnée
str(DataBio)
#mise en place des donnée qualitative
DataBio$ExpT1 = as.factor(DataBio$ExpT1)
DataBio$ExpT2 = as.factor(DataBio$ExpT2)
DataBio$ExpT3 = as.factor(DataBio$ExpT3)
print(summary(DataBio))
if (!require("corrplot")) install.packages("corrplot")
library(corrplot)
M_cor = cor(DataBio[1:36])
corrplot(M_cor, method="ellipse")
#on constate ici, une faible correlation de la part de T1 envers les autre traitement, et que le traitement 1 fonctionne particulièrement mal à la 6ème heure contrairement aux autres.
```
```{r echo=F}
#Pour installer les packages
if (!require("FactoMineR")) install.packages("FactoMineR")
if (!require("factoextra")) install.packages("factoextra")
if (!require("corrplot")) install.packages("corrplot")
library(FactoMineR)
library(factoextra)
library(corrplot)
# A présent, on passe sur l'ACP Centrée. Pour cela, on commence par centrer notre jeu de données.
#ACP Centrée réduite (Toutes les variables ont la même importance)
Tt_sH_Rr <- DataBio[c(1: 36)]
DataBioC <- scale(Tt_sH_Rr, center=TRUE, scale=T)

# On fait la transposée pour avoir : les Tt_sH_Rr décrits par les gènes (J'avour je suis pas sûr à 100% pour ce passage. Sinon on peut enlever la transposée)
ACP_DataBio_reduite <- PCA(DataBio[c(1:36)],  scale.unit = T, graph = F)
ACP_DataBio_reduite$eig
fviz_eig(ACP_DataBio_reduite,addlabels = TRUE, ylim = c(0, 100), main = "Valeurs propres")
# Projection des individus
fviz_pca_ind(ACP_DataBio_reduite, geom = c("point"),col.ind = "cos2", gradient.cols = c("blue", "red"), repel = TRUE, title = "Projection des individus (Tt_sH_Rr)")

```

```{r,echo=T, error=F,warning=F,message=F}
if (!require("forcats")) install.packages("forcats")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("corrplot")) install.packages("corrplot")
if (!require("FactoMineR")) install.packages("FactoMineR")
if (!require("factoextra")) install.packages("factoextra")
if (!require("mclust")) install.packages("mclust")
if (!require("cluster")) install.packages("cluster")
if (!require("ppclust")) install.packages("ppclust")
if (!require("circlize")) install.packages("circlize")
if (!require("ggalluvial")) install.packages("ggalluvial")
library(forcats)
library(ggplot2)
library(corrplot)
library(reshape2)

library(FactoMineR)
library(factoextra)

library(mclust)
library(cluster)
library(ppclust)

library(circlize)
library(ggalluvial)

# Maintenant que l'ACP a été effectuée, on fait un clustering des classes à l'aide de la méthode K-means.

# Avant de débuter le clustering avec la méthode K-means, il faut déterminer le nombre de classes.

Kmax<-20
reskmeanscl<-matrix(0,nrow=nrow(DataBio),ncol=Kmax-1)
Iintra<-NULL
for (k in 1:Kmax){
  resaux<-kmeans(DataBioCR,centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss) # tot.withinss correspond à la somme des composantes au carré des éléments du cluster par cluster
}

df<-data.frame(K=1:20,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+
  geom_line()+
  geom_point()+
  xlab("Nombre de classes")+
  ylab("Inertie intraclasse")

# Avec cette méthode, on dirait que le coude correspond lorsque le nombre de classes est de 2.
# On va alors utiliser 2 classes pour la méthode des K-means.

reskmeans<-kmeans(DataBioCR,centers = 2)
fviz_cluster(reskmeans,data=Tt_sH_Rr,
             ellipse.type="norm",labelsize=8,
             geom=c("point"))+ggtitle("")
#fviz_pca_ind(resacp,col.ind=as.factor(reskmeans$cluster),geom = c("point"),axes=c(1,2))

# A présent, on va essayer une autre méthode, la méthode hiérarchique.

# D'une part, on fait le calcul de la matrice de distances
dist_matrix <- dist(DataBioCR, method = "euclidean")
# Clustering hiérarchique avec la méthode de liaison "ward.D2", on peut aussi faire avec "single", "complete","average" ...
hc <- hclust(dist_matrix, method = "ward.D2") 
# Afficher le dendrogramme
fviz_dend(hc,k=2,show_labels = FALSE,
rect = TRUE, rect_fill = TRUE,palette = "npg",
rect_border = "npg",
labels_track_height = 0.8)+ggtitle("")

# (Le temps de chargement est plutôt long, C'est NORMAL)

```



```{r echo=F}
# A présent,on va essayer de construire la matrice DataExpMoy. C'est une matrice de taille G * 18. Le nombre de lignes correspond aux gènes et les colonnes correspondent aux moyennes de T1,T2,T3 pour chaque heure. On a alors :
# colonne 1 : moyenne(T1_1H_R1/2)
# colonne 2 : moyenne(T1_2H_R1/2)
# colonne 3 : moyenne(T1_3H_R1/2)
# colonne 4 : moyenne(T1_4H_R1/2)
# colonne 5 : moyenne(T1_5H_R1/2)
# colonne 6 : moyenne(T1_6H_R1/2)
# colonne 7 : moyenne(T2_1H_R1/2)
# colonne 8 : moyenne(T2_2H_R1/2)
# ...
# colonne 18 : moyenne(T3_6H_R1/2)
# On essaye de créer cette matrice :
cols_T1_R1 <- grep("^T1_.*_R1$", colnames(DataBio))  # T1 pour R1
cols_T1_R2 <- grep("^T1_.*_R2$", colnames(DataBio))  # T1 pour R2

cols_T2_R1 <- grep("^T2_.*_R1$", colnames(DataBio))  # T2 pour R1
cols_T2_R2 <- grep("^T2_.*_R2$", colnames(DataBio))  # T2 pour R2

cols_T3_R1 <- grep("^T3_.*_R1$", colnames(DataBio))  # T3 pour R1
cols_T3_R2 <- grep("^T3_.*_R2$", colnames(DataBio))  # T3 pour R2

# Moyenne pour T1
T1_means <- (DataBio[, cols_T1_R1] + DataBio[, cols_T1_R2]) / 2

# Moyenne pour T2
T2_means <- (DataBio[, cols_T2_R1] + DataBio[, cols_T2_R2]) / 2

# Moyenne pour T3
T3_means <- (DataBio[, cols_T3_R1] + DataBio[, cols_T3_R2]) / 2

MatriceDataExpMoy <- cbind(T1_means, T2_means, T3_means)
DataExpMoy <- as.data.frame(cbind(T1_means, T2_means, T3_means))

# Pour vérifier la taille
dim(DataExpMoy)  # Devrait être 542 × 18 (c'est bon)

# On utilise T1 /T2 /T3 pour Identifier les gènes particulièrement influents pour un traitement spécifique.
# Ajouter les colonnes ExpT1, ExpT2, ExpT3 pour un filtrage
DataExpMoy_full <- cbind(MatriceDataExpMoy, ExpT1 = DataBio$ExpT1, ExpT2 = DataBio$ExpT2, ExpT3 = DataBio$ExpT3)

# Moyenne des gènes surexprimés pour T1 à 6 heures
mean_sur_T1_6H <- mean(DataExpMoy_full[DataExpMoy_full$ExpT1 == "Sur", "T1_6H"])
print(mean_sur_T1_6H)
# On fait la ACP de ce nouveau jeu de données

DataExpMoyC <- scale(t(DataExpMoy), center=TRUE)
# On fait la transposée pour avoir : les Tt_sH_Rr décrits par les gènes (J'avour je suis pas sûr à 100% pour ce passage. Sinon on peut enlever la transposée)
ACP_DataExpMoy_reduite <- PCA(DataExpMoyC,  scale.unit = T, graph = F)
ACP_DataExpMoy_reduite$eig
fviz_eig(ACP_DataExpMoy_reduite,addlabels = TRUE, ylim = c(0, 100), main = "Valeurs propres")
# Projection des DataExpMoy
fviz_pca_ind(ACP_DataExpMoy_reduite, geom = c("point"),col.ind = "cos2", gradient.cols = c("blue", "red"), repel = TRUE, title = "Projection des DataExpMoy")

```

```{r,echo=T, error=F,warning=F,message=F}
if (!require("forcats")) install.packages("forcats")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("corrplot")) install.packages("corrplot")
if (!require("FactoMineR")) install.packages("FactoMineR")
if (!require("factoextra")) install.packages("factoextra")
if (!require("mclust")) install.packages("mclust")
if (!require("cluster")) install.packages("cluster")
if (!require("ppclust")) install.packages("ppclust")
if (!require("circlize")) install.packages("circlize")
if (!require("ggalluvial")) install.packages("ggalluvial")
library(forcats)
library(ggplot2)
library(corrplot)
library(reshape2)

library(FactoMineR)
library(factoextra)

library(mclust)
library(cluster)
library(ppclust)

library(circlize)
library(ggalluvial)

# Maintenant que l'ACP a été effectuée, on fait un clustering des classes à l'aide de la méthode K-means.

# Avant de débuter le clustering avec la méthode K-means, il faut déterminer le nombre de classes.

Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(DataExpMoyCR),ncol=Kmax-1)
Iintra<-NULL
for (k in 1:Kmax){
  resaux<-kmeans(DataExpMoyCR,centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss) # tot.withinss correspond à la somme des composantes au carré des éléments du cluster par cluster
}

df<-data.frame(K=1:15,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+
  geom_line()+
  geom_point()+
  xlab("Nombre de classes")+
  ylab("Inertie intraclasse")

# Avec cette méthode, on dirait que le coude correspond lorsque le nombre de classes est de 2.
# On va alors utiliser 2 classes pour la méthode des K-means.

ExpMoykmeans<-kmeans(DataExpMoyCR,centers = 2)
fviz_cluster(ExpMoykmeans,data=DataExpMoyCR,ellipse.type="norm",labelsize=8,geom=c("point"))+ggtitle("")
#fviz_pca_ind(resacp,col.ind=as.factor(ExpMoykmean$cluster),geom = c("point"),axes=c(1,2))

# A présent, on va essayer une autre méthode, la méthode hiérarchique.

# D'une part, on fait le calcul de la matrice de distances
dist_matrix_ExpMoy <- dist(DataExpMoyCR, method = "euclidean")
# Clustering hiérarchique avec la méthode de liaison "ward.D2", on peut aussi faire avec "single", "complete","average" ...
hc_ExpMoy <- hclust(dist_matrix_ExpMoy, method = "ward.D2") 
# Afficher le dendrogramme
fviz_dend(hc_ExpMoy,k=2,show_labels = FALSE,
rect = TRUE, rect_fill = TRUE,palette = "npg",
rect_border = "npg",
labels_track_height = 0.8)+ggtitle("")
# (Le temps de chargement est plutôt long)

```


